{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General\n",
    "* RUNNING ON COLAB: Make a folder in your Google Drive called `datascience_data`, and upload all the .csv files there\n",
    "* RUNNING LOCALLY: Make a folder called `datascience_data` in the same directory as this notebook, and put all the .csv files there\n",
    "\n",
    "### Recommendation\n",
    "* In order to get a recommendation, provide a **full title** of a movie that you like.\n",
    "\n",
    "\n",
    "### TODO:\n",
    "* We should use clustering, but on what? Genres? Tags? Both?\n",
    "    * I tried doing clustering algorithm on the tdif_matrix, but it did not give great results compared to the current method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/p6ywqf2n265gpy7nfz_lhs580000gn/T/ipykernel_83916/2163399603.py:21: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_metadata_df = pd.read_csv(drive_path + '/' + file_names[4])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# # Run on Colab\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# Define the path to the file in Google Drive\n",
    "# drive_path = 'drive/My Drive/datascience_data'\n",
    "\n",
    "# Run on local (folder: data)\n",
    "drive_path = 'datascience_data'\n",
    "\n",
    "# Define the file names\n",
    "file_names = ['credits.csv', 'keywords.csv', 'links.csv', 'links_small.csv', 'movies_metadata.csv', 'ratings.csv', 'ratings_small.csv']\n",
    "\n",
    "# Load the data into Pandas DataFrames\n",
    "# credits_df = pd.read_csv(drive_path + '/' + file_names[0])\n",
    "keywords_df = pd.read_csv(drive_path + '/' + file_names[1])\n",
    "# links_df = pd.read_csv(drive_path + '/' + file_names[2])\n",
    "# links_small_df = pd.read_csv(drive_path + '/' + file_names[3])\n",
    "movies_metadata_df = pd.read_csv(drive_path + '/' + file_names[4])\n",
    "# ratings_df = pd.read_csv(drive_path + '/' + file_names[5])\n",
    "# ratings_small_df = pd.read_csv(drive_path + '/' + file_names[6])\n",
    "\n",
    "\n",
    "# Display the first few rows of each dataframe to understand their structure\n",
    "dataframes = {\n",
    "    \"keywords\": keywords_df.head(),\n",
    "    # \"links_small\": links_small_df.head(),\n",
    "    # \"links\": links_df.head(),\n",
    "    \"movies_metadata\": movies_metadata_df.head(),\n",
    "    # \"ratings_small\": ratings_small_df.head()\n",
    "}\n",
    "\n",
    "# dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing\n",
    "Let's begin with the inspection and cleaning of each dataset. I'll start by checking for missing values, duplicates, and data types to ensure that the data is consistent and ready for merging. After that, I'll merge the relevant information from each dataset into a single DataFrame for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45433 entries, 0 to 45432\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        45433 non-null  int64 \n",
      " 1   title     45430 non-null  object\n",
      " 2   overview  44479 non-null  object\n",
      " 3   keywords  45432 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/p6ywqf2n265gpy7nfz_lhs580000gn/T/ipykernel_83916/1208202004.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  keywords_clean['id'] = keywords_clean['id'].astype(int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "       id                        title  \\\n",
       " 0    862                    Toy Story   \n",
       " 1   8844                      Jumanji   \n",
       " 2  15602             Grumpier Old Men   \n",
       " 3  31357            Waiting to Exhale   \n",
       " 4  11862  Father of the Bride Part II   \n",
       " \n",
       "                                             overview  \\\n",
       " 0  Led by Woody, Andy's toys live happily in his ...   \n",
       " 1  When siblings Judy and Peter discover an encha...   \n",
       " 2  A family wedding reignites the ancient feud be...   \n",
       " 3  Cheated on, mistreated and stepped on, the wom...   \n",
       " 4  Just when George Banks has recovered from his ...   \n",
       " \n",
       "                                             keywords  \n",
       " 0  [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...  \n",
       " 1  [{'id': 10090, 'name': 'board game'}, {'id': 1...  \n",
       " 2  [{'id': 1495, 'name': 'fishing'}, {'id': 12392...  \n",
       " 3  [{'id': 818, 'name': 'based on novel'}, {'id':...  \n",
       " 4  [{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...  )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data inspection and cleaning for each dataset\n",
    "\n",
    "# Inspect for duplicates, null values and data types in movies_metadata\n",
    "movies_metadata_clean = movies_metadata_df.drop_duplicates(subset='id')\n",
    "movies_metadata_clean = movies_metadata_clean[movies_metadata_clean['id'].apply(lambda x: str(x).isdigit())]\n",
    "movies_metadata_clean['id'] = movies_metadata_clean['id'].astype(int)\n",
    "\n",
    "# Check for null values and duplicates in the keywords dataset\n",
    "keywords_clean = keywords_df.drop_duplicates('id')\n",
    "keywords_clean['id'] = keywords_clean['id'].astype(int)\n",
    "\n",
    "# Now, merge the datasets on 'id' column\n",
    "# We only need the 'id', 'title', and 'overview' from movies_metadata\n",
    "# And the 'keywords' from the keywords dataset\n",
    "merged_df = pd.merge(movies_metadata_clean[['id', 'title', 'overview']],\n",
    "                     keywords_clean,\n",
    "                     on='id',\n",
    "                     how='left')\n",
    "\n",
    "# Display the merged DataFrame structure and check for nulls\n",
    "merged_df.info(), merged_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle the missing values in the overview and keywords columns, which may involve filling or removing the missing entries.\n",
    "Preprocess the overview and keywords text data. This involves converting the JSON-like string in the keywords column into a workable format, tokenizing, and cleaning the text (e.g., removing stop words, punctuation, and stemming or lemmatization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    Led by Woody, Andy's toys live happily in his ...\n",
       " 1    When siblings Judy and Peter discover an encha...\n",
       " 2    A family wedding reignites the ancient feud be...\n",
       " 3    Cheated on, mistreated and stepped on, the wom...\n",
       " 4    Just when George Banks has recovered from his ...\n",
       " Name: combined, dtype: object,\n",
       " id              0\n",
       " title           3\n",
       " overview        0\n",
       " keywords        0\n",
       " keyword_list    0\n",
       " combined        0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling missing values\n",
    "# For the 'overview' column, if the overview is missing, we can fill it with an empty string\n",
    "# For the 'keywords' column, if the keywords are missing, we can also fill it with an empty string\n",
    "\n",
    "merged_df['overview'] = merged_df['overview'].fillna('')\n",
    "merged_df['keywords'] = merged_df['keywords'].fillna('[]')\n",
    "\n",
    "# Now we need to convert the 'keywords' column from a JSON-like string to an actual list of keywords\n",
    "import json\n",
    "\n",
    "# A function to parse the keywords correctly, handling any errors in the JSON decoding process\n",
    "def parse_keywords(keyword_string):\n",
    "    try:\n",
    "        return json.loads(keyword_string.replace(\"'\", \"\\\"\"))\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        return []  # In case of error, return an empty list\n",
    "\n",
    "# Apply the function to the 'keywords' column\n",
    "merged_df['keywords'] = merged_df['keywords'].apply(parse_keywords)\n",
    "\n",
    "# Extract just the names of the keywords to a new column 'keyword_list'\n",
    "merged_df['keyword_list'] = merged_df['keywords'].apply(lambda x: [d['name'] for d in x])\n",
    "\n",
    "# We will also create a 'combined' column that concatenates the overview and the keyword list into a single string\n",
    "# This is what we will use for TF-IDF vectorization\n",
    "merged_df['combined'] = merged_df['overview'] + ' ' + merged_df['keyword_list'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Display the final structure of the DataFrame and the first few rows of the 'combined' column\n",
    "merged_df['combined'].head(), merged_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing values in the overview and keywords columns have been handled, and a new combined column has been created by concatenating the overview and the keyword names. This column will serve as the corpus for TF-IDF vectorization.\n",
    "\n",
    "The final structure indicates that there are no missing values in the key columns used for TF-IDF. However, there are 3 entries with missing titles, which should not affect the recommendation system, as the recommendations are based on the content, not the title itself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>keywords</th>\n",
       "      <th>keyword_list</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>[{'id': 931, 'name': 'jealousy'}, {'id': 4290,...</td>\n",
       "      <td>[jealousy, toy, boy, friendship, friends, riva...</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>[{'id': 1495, 'name': 'fishing'}, {'id': 12392...</td>\n",
       "      <td>[fishing, best friend, duringcreditsstinger, o...</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>[{'id': 818, 'name': 'based on novel'}, {'id':...</td>\n",
       "      <td>[based on novel, interracial relationship, sin...</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>[{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...</td>\n",
       "      <td>[baby, midlife crisis, confidence, aging, daug...</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                        title  \\\n",
       "0    862                    Toy Story   \n",
       "1   8844                      Jumanji   \n",
       "2  15602             Grumpier Old Men   \n",
       "3  31357            Waiting to Exhale   \n",
       "4  11862  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   \n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "3  Cheated on, mistreated and stepped on, the wom...   \n",
       "4  Just when George Banks has recovered from his ...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...   \n",
       "1                                                 []   \n",
       "2  [{'id': 1495, 'name': 'fishing'}, {'id': 12392...   \n",
       "3  [{'id': 818, 'name': 'based on novel'}, {'id':...   \n",
       "4  [{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...   \n",
       "\n",
       "                                        keyword_list  \\\n",
       "0  [jealousy, toy, boy, friendship, friends, riva...   \n",
       "1                                                 []   \n",
       "2  [fishing, best friend, duringcreditsstinger, o...   \n",
       "3  [based on novel, interracial relationship, sin...   \n",
       "4  [baby, midlife crisis, confidence, aging, daug...   \n",
       "\n",
       "                                            combined  \n",
       "0  Led by Woody, Andy's toys live happily in his ...  \n",
       "1  When siblings Judy and Peter discover an encha...  \n",
       "2  A family wedding reignites the ancient feud be...  \n",
       "3  Cheated on, mistreated and stepped on, the wom...  \n",
       "4  Just when George Banks has recovered from his ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.to_csv('movies_metadata_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreasolborg/anaconda3/lib/python3.11/site-packages/scipy/sparse/_base.py:659: RuntimeWarning: divide by zero encountered in divide\n",
      "  recip = np.true_divide(1., other)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the 'combined' column to a TF-IDF matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(merged_df['combined'])\n",
    "\n",
    "# Output the shape of the TF-IDF matrix\n",
    "tfidf_matrix.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TF-IDF vectorization is complete. The resulting TF-IDF matrix has dimensions of 45433Ã—77452, indicating that there are 45,433 movies and 77,452 unique words (after removing stop words) across the combined text corpus.\n",
    "\n",
    "With this matrix, we can now calculate the cosine similarity between movies and build the recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Recommendation System with Pairwise Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high memory requirements of storing such a large dense matrix, we use an alternative approach: a more memory-efficient method such as pairwise_distances from sklearn.metrics with metric='cosine', which computes similarity scores on the fly and doesn't require storing a large matrix in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18244                                The Dark Knight Rises\n",
       "15505                           Batman: Under the Red Hood\n",
       "1328                                        Batman Returns\n",
       "10119                                        Batman Begins\n",
       "585                                                 Batman\n",
       "150                                         Batman Forever\n",
       "20223              Batman: The Dark Knight Returns, Part 2\n",
       "40944    LEGO DC Comics Super Heroes: Batman: Be-Leaguered\n",
       "21181    Batman Unmasked: The Psychology of the Dark Kn...\n",
       "9228                    Batman Beyond: Return of the Joker\n",
       "41952    Batman Beyond Darwyn Cooke's Batman 75th Anniv...\n",
       "32096                     Batman Unlimited: Monster Mayhem\n",
       "41946                                The Lego Batman Movie\n",
       "3094                          Batman: Mask of the Phantasm\n",
       "19783              Batman: The Dark Knight Returns, Part 1\n",
       "41424    LEGO DC Comics Super Heroes: Justice League - ...\n",
       "39598                             Batman: The Killing Joke\n",
       "31049                   Batman v Superman: Dawn of Justice\n",
       "9167             The Batman Superman Movie: World's Finest\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# Construct a reverse map of indices and movie titles\n",
    "indices = pd.Series(merged_df.index, index=merged_df['title']).drop_duplicates()\n",
    "\n",
    "# Instead of calculating the dense matrix all at once, we'll calculate the cosine similarity on-the-fly\n",
    "# For memory efficiency, we'll use pairwise_distances with metric 'cosine' which is equivalent to 1 - cosine_similarity\n",
    "\n",
    "# Function to get recommendations based on cosine similarity, computed on-the-fly\n",
    "def get_recommendations_pairwise_distances(title, tfidf_matrix=tfidf_matrix, indices=indices):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Compute the cosine similarity between this movie and all others in the dataset\n",
    "    cosine_similarities = 1 - pairwise_distances(tfidf_matrix[idx], tfidf_matrix, metric='cosine')\n",
    "    \n",
    "    # Get the scores of all movies\n",
    "    sim_scores = list(enumerate(cosine_similarities[0]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:20]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return merged_df['title'].iloc[movie_indices]\n",
    "\n",
    "# Test the system with a movie\n",
    "get_recommendations_pairwise_distances(\"The Dark Knight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Nearest Neighbors with Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18244                                The Dark Knight Rises\n",
       "15505                           Batman: Under the Red Hood\n",
       "1328                                        Batman Returns\n",
       "10119                                        Batman Begins\n",
       "585                                                 Batman\n",
       "150                                         Batman Forever\n",
       "20223              Batman: The Dark Knight Returns, Part 2\n",
       "40944    LEGO DC Comics Super Heroes: Batman: Be-Leaguered\n",
       "21181    Batman Unmasked: The Psychology of the Dark Kn...\n",
       "9228                    Batman Beyond: Return of the Joker\n",
       "28681                                      The Dark Knight\n",
       "2973                                             Kagemusha\n",
       "34830                                     West Of Shanghai\n",
       "32656                                            Turbo Kid\n",
       "17995                       Prisoners of the Lost Universe\n",
       "17103                                   The Storm Warriors\n",
       "6937                                                  Hero\n",
       "22097                                              Ninja 1\n",
       "4879                                       Black Hawk Down\n",
       "13271                             The General Died at Dawn\n",
       "9240                Dark Prince: The True Story of Dracula\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Using the NearestNeighbors class to find the most similar items\n",
    "# Initializing the NearestNeighbors model with cosine similarity\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "\n",
    "# Fitting the model on our TF-IDF matrix\n",
    "model_knn.fit(tfidf_matrix)\n",
    "\n",
    "# Function to get recommendations using Nearest Neighbors\n",
    "def get_recommendations_knn(title, model_knn=model_knn, indices=indices):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Find the k-neighbors of a point\n",
    "    distances, indices = model_knn.kneighbors(tfidf_matrix[idx], n_neighbors=11)\n",
    "\n",
    "    # Get the indices of the nearest neighbors (excluding itself)\n",
    "    nearest_indices = indices.flatten()[1:]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return merged_df['title'].iloc[nearest_indices]\n",
    "\n",
    "# Test the system with a movie\n",
    "get_recommendations_knn('The Dark Knight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Methods for Computing Similarity\n",
    "There are indeed other methods to compute similarities between items in a recommendation system context, which can be more memory efficient. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
